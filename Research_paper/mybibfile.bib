@article{WCE,
author = {Muruganantham, Prabhananthakumar and Balakrishnan, Senthil},
year = {2021},
month = {06},
pages = {83-92},
title = {A survey on deep learning models for wireless capsule endoscopy image analysis},
volume = {2},
journal = {International Journal of Cognitive Computing in Engineering},
doi = {10.1016/j.ijcce.2021.04.002}
}


@article{WCE2,
title = {Recent developments in wireless capsule endoscopy imaging: Compression and summarization techniques},
journal = {Computers in Biology and Medicine},
volume = {149},
pages = {106087},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106087},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522007958},
author = {Sushma B. and Aparna P.},
}


@article{WCE3,
author = {Gilja, Odd and Hatlebakk, Jan and Ødegaard, Svein and Berstad, Arnold and Viola, Ivan and Giertsen, Christopher and Hausken, Trygve and Gregersen, Hans},
year = {2007},
month = {04},
pages = {1408-21},
title = {Advanced imaging and visualization in gastrointestinal disorders},
volume = {13},
journal = {World journal of gastroenterology : WJG},
doi = {10.3748/wjg.v13.i9.1408}
}

@article {lowres,
	Title = {The Effect of Image Resolution on Deep Learning in Radiography},
	Author = {Sabottke, Carl F and Spieler, Bradley M},
	DOI = {10.1148/ryai.2019190015},
	Number = {1},
	Volume = {2},
	Month = {January},
	Year = {2020},
	Journal = {Radiology. Artificial intelligence},
	ISSN = {2638-6100},
	Pages = {e190015},
	URL = {https://europepmc.org/articles/PMC8017385},
}


@article{SISR,
author = {Chen, Honggang and He, Xiaohai and Ren, Chao and Qing, Linbo and Teng, Qizhi},
year = {2017},
month = {09},
pages = {},
title = {CISRDCNN: Super-resolution of compressed images using deep convolutional neural networks},
volume = {285},
journal = {Neurocomputing},
doi = {10.1016/j.neucom.2018.01.043}
}

@inproceedings{diffalendo,
author = {Kasem, Hossam and Hung, Kwok-Wai and Jiang, Jianmin},
year = {2018},
month = {08},
pages = {2688-2692},
title = {Revised Spatial Transformer Network towards Improved Image Super-resolutions},
doi = {10.1109/ICPR.2018.8546080}
}

@inproceedings{SRCNN,
  title={Accelerating the super-resolution convolutional neural network},
  author={Dong, Chao and Loy, Chen Change and Tang, Xiaoou},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
  pages={391--407},
  year={2016},
  organization={Springer}
}

@INPROCEEDINGS{VDSR,
  author={Kim, Jiwon and Lee, Jung Kwon and Lee, Kyoung Mu},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Accurate Image Super-Resolution Using Very Deep Convolutional Networks}, 
  year={2016},
  volume={},
  number={},
  pages={1646-1654},
  doi={10.1109/CVPR.2016.182}}


@inproceedings{DRCN,
  title={Deeply-recursive convolutional network for image super-resolution},
  author={Kim, Jiwon and Lee, Jung Kwon and Lee, Kyoung Mu},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1637--1645},
  year={2016}
}

@inproceedings{ResNet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@inproceedings{EDSR,
  title={Enhanced deep residual networks for single image super-resolution},
  author={Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Mu Lee, Kyoung},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={136--144},
  year={2017}
}

@inproceedings{SRDensenet,
  title={Image super-resolution using dense skip connections},
  author={Tong, Tong and Li, Gen and Liu, Xiejie and Gao, Qinquan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4799--4807},
  year={2017}
}

@inproceedings{RCAN,
  title={Image super-resolution using very deep residual channel attention networks},
  author={Zhang, Yulun and Li, Kunpeng and Li, Kai and Wang, Lichen and Zhong, Bineng and Fu, Yun},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={286--301},
  year={2018}
}

@inproceedings{perploss,
author = {Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
year = {2016},
month = {10},
pages = {694-711},
title = {Perceptual Losses for Real-Time Style Transfer and Super-Resolution},
volume = {9906},
isbn = {978-3-319-46474-9},
doi = {10.1007/978-3-319-46475-6_43}
}

@article{perpsimi,
author = {Gatys, Leon and Ecker, Alexander and Bethge, Matthias},
year = {2015},
month = {05},
pages = {},
title = {Texture synthesis and the controlled generation of natural stimuli using convolutional neural networks}
}

@article{perpsimi2,
author = {Bruna, Joan and Sprechmann, Pablo and Lecun, Yann},
year = {2015},
month = {11},
pages = {},
title = {Super-Resolution with Deep Convolutional Sufficient Statistics}
}

@article{contextloss,
author = {Mechrez, Roey and Talmi, Itamar and Shama, Firas and Zelnik-Manor, Lihi},
year = {2018},
month = {03},
pages = {},
title = {Learning to Maintain Natural Image Statistics}
}

@INPROCEEDINGS{SRGAN,
  author={Ledig, Christian and Theis, Lucas and Huszár, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network}, 
  year={2017},
  volume={},
  number={},
  pages={105-114},
  doi={10.1109/CVPR.2017.19}}

@ARTICLE{MPDGAN,
  author={Lee, Oh-Young and Shin, Yoon-Ho and Kim, Jong-Ok},
  journal={IEEE Access}, 
  title={Multi-Perspective Discriminators-Based Generative Adversarial Network for Image Super Resolution}, 
  year={2019},
  volume={7},
  number={},
  pages={136496-136510},
  doi={10.1109/ACCESS.2019.2942779}}

@unknown{DMGAN,
author = {Zhu, Minfeng and Pan, Pingbo and Chen, Wei and Yang, Yi},
year = {2019},
month = {04},
pages = {},
title = {DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis}
}

@article{ CGAN,
author = {Mirza, Mehdi and Osindero, Simon},
year = {2014},
month = {11},
pages = {},
title = {Conditional Generative Adversarial Nets}
}

@article{LAPGAN,
author = {Denton, Emily and Chintala, Soumith and Szlam, Arthur and Fergus, Rob},
year = {2015},
month = {06},
pages = {},
title = {Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks}
}


@INPROCEEDINGS{CycleGAN,
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks}, 
  year={2017},
  volume={},
  number={},
  pages={2242-2251},
  doi={10.1109/ICCV.2017.244}}

@inproceedings{ESRGAN,
  title={Esrgan: Enhanced super-resolution generative adversarial networks},
  author={Wang, Xintao and Yu, Ke and Wu, Shixiang and Gu, Jinjin and Liu, Yihao and Dong, Chao and Qiao, Yu and Change Loy, Chen},
  booktitle={Proceedings of the European conference on computer vision (ECCV) workshops},
  pages={0--0},
  year={2018}
}

@unknown{RAGAN,
author = {Jolicoeur-Martineau, Alexia},
year = {2018},
month = {07},
pages = {},
title = {The relativistic discriminator: a key element missing from standard GAN}
}

@article{Capsule,
author = {Muruganantham, Prabhananthakumar and Balakrishnan, Senthil},
year = {2021},
month = {06},
pages = {83-92},
title = {A survey on deep learning models for wireless capsule endoscopy image analysis},
volume = {2},
journal = {International Journal of Cognitive Computing in Engineering},
doi = {10.1016/j.ijcce.2021.04.002}
}

@article{data,
  title={Kvasir-Capsule, a video capsule endoscopy dataset},
  author={Smedsrud, Pia H and Thambawita, Vajira and Hicks, Steven A and Gjestang, Henrik and Nedrejord, Oda Olsen and N{\ae}ss, Espen and Borgli, Hanna and Jha, Debesh and Berstad, Tor Jan Derek and Eskeland, Sigrun L and others},
  journal={Scientific Data},
  volume={8},
  number={1},
  pages={142},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{DLSR,
author = {Wang, Zhihao and Chen, Jian and Hoi, Steven},
year = {2020},
month = {03},
pages = {1-1},
title = {Deep Learning for Image Super-Resolution: A Survey},
volume = {PP},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
doi = {10.1109/TPAMI.2020.2982166}
}

@inproceedings{VDRCB,
author = {Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Lee, Kyoung Mu},
year = {2017},
month = {07},
pages = {1132-1140},
title = {Enhanced Deep Residual Networks for Single Image Super-Resolution},
doi = {10.1109/CVPRW.2017.151}
}


@article{Adam,
author = {Kingma, Diederik and Ba, Jimmy},
year = {2014},
month = {12},
pages = {},
title = {Adam: A Method for Stochastic Optimization},
journal = {International Conference on Learning Representations}
}

@article{GAN,
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Y.},
year = {2014},
month = {06},
pages = {},
title = {Generative Adversarial Networks},
volume = {3},
journal = {Advances in Neural Information Processing Systems},
doi = {10.1145/3422622}
}

@article{PSNR,
author = {Fardo, Fernando and Conforto, Victor and Oliveira, Francisco and Rodrigues, Paulo},
year = {2016},
month = {05},
pages = {},
title = {A Formal Evaluation of PSNR as Quality Measurement Parameter for Image Segmentation Algorithms}
}

@article{SSIM,
author = {Wang, Zhou and Bovik, Alan and Sheikh, Hamid and Simoncelli, Eero},
year = {2004},
month = {05},
pages = {600 - 612},
title = {Image Quality Assessment: From Error Visibility to Structural Similarity},
volume = {13},
journal = {Image Processing, IEEE Transactions on},
doi = {10.1109/TIP.2003.819861}
}

@article{LPIPS,
author = {Zhang, Richard and Isola, Phillip and Efros, Alexei and Shechtman, Eli and Wang, Oliver},
year = {2018},
month = {01},
pages = {},
title = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric}
}

@ARTICLE{EndoL2h,
  author={Almalioglu, Yasin and Bengisu Ozyoruk, Kutsev and Gokce, Abdulkadir and Incetan, Kagan and Irem Gokceler, Guliz and Ali Simsek, Muhammed and Ararat, Kivanc and Chen, Richard J. and Durr, Nicholas J. and Mahmood, Faisal and Turan, Mehmet},
  journal={IEEE Transactions on Medical Imaging}, 
  title={EndoL2H: Deep Super-Resolution for Capsule Endoscopy}, 
  year={2020},
  volume={39},
  number={12},
  pages={4297-4309},
  doi={10.1109/TMI.2020.3016744}}

  @article{L10,
title = {Image super-resolution using progressive generative adversarial networks for medical image analysis},
journal = {Computerized Medical Imaging and Graphics},
volume = {71},
pages = {30-39},
year = {2019},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2018.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0895611118305871},
author = {Dwarikanath Mahapatra and Behzad Bozorgtabar and Rahil Garnavi},
keywords = {Progressive generative models, Adversarial networks, Image super-resolution, Retinal fundus, MRI, Pathology},
abstract = {Anatomical landmark segmentation and pathology localisation are important steps in automated analysis of medical images. They are particularly challenging when the anatomy or pathology is small, as in retinal images (e.g. vasculature branches or microaneurysm lesions) and cardiac MRI, or when the image is of low quality due to device acquisition parameters as in magnetic resonance (MR) scanners. We propose an image super-resolution method using progressive generative adversarial networks (P-GANs) that can take as input a low-resolution image and generate a high resolution image of desired scaling factor. The super resolved images can be used for more accurate detection of landmarks and pathologies. Our primary contribution is in proposing a multi-stage model where the output image quality of one stage is progressively improved in the next stage by using a triplet loss function. The triplet loss enables stepwise image quality improvement by using the output of the previous stage as the baseline. This facilitates generation of super resolved images of high scaling factor while maintaining good image quality. Experimental results for image super-resolution show that our proposed multi stage P-GAN outperforms competing methods and baseline GANs. The super resolved images when used for landmark and pathology detection result in accuracy levels close to those obtained when using the original high resolution images. We also demonstrate our methods effectiveness on magnetic resonance (MR) images, thus establishing its broader applicability}
}